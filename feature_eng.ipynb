{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some feature engineering good examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Building pipeline\n",
    "\n",
    "https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pmlb\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (12, 8)})\n",
    "\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"The DataFrame does not include the columns: %s\" % cols_error)\n",
    "\n",
    "\n",
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "\n",
    "\n",
    "df = pmlb.fetch_data('churn', return_X_y=False)\n",
    "\n",
    "# Remove the target column and the phone number\n",
    "x_cols = [c for c in df if c not in [\"target\", \"phone number\"]]\n",
    "\n",
    "binary_features = [\"international plan\", \"voice mail plan\"]\n",
    "categorical_features = [\"state\", \"area code\"]\n",
    "\n",
    "# Column types are defaulted to floats\n",
    "X = (\n",
    "    df\n",
    "    .drop([\"target\"], axis=1)\n",
    "    .astype(float)\n",
    ")\n",
    "X[binary_features] = X[binary_features].astype(\"bool\")\n",
    "\n",
    "# Categorical features can't be set all at once\n",
    "for f in categorical_features:\n",
    "    X[f] = X[f].astype(\"category\")\n",
    "\n",
    "y = df.target\n",
    "\n",
    "# Randomly set 500 items as missing values\n",
    "random.seed(42)\n",
    "num_missing = 500\n",
    "indices = [(row, col) for row in range(X.shape[0]) for col in range(X.shape[1])]\n",
    "for row, col in random.sample(indices, num_missing):\n",
    "    X.iat[row, col] = np.nan\n",
    "\n",
    "# Partition data set into training/test split (2 to 1 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3., random_state=42)\n",
    "\n",
    "\n",
    "preprocess_pipeline = make_pipeline(\n",
    "    ColumnSelector(columns=x_cols),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            TypeSelector(np.number),\n",
    "            Imputer(strategy=\"median\"),\n",
    "            StandardScaler()\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            TypeSelector(\"category\"),\n",
    "            Imputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder()\n",
    "        )),\n",
    "        (\"boolean_features\", make_pipeline(\n",
    "            TypeSelector(\"bool\"),\n",
    "            Imputer(strategy=\"most_frequent\")\n",
    "        ))\n",
    "    ])\n",
    ")\n",
    "\n",
    "classifier_pipeline = make_pipeline(\n",
    "    preprocess_pipeline,\n",
    "    SVC(kernel=\"rbf\", random_state=42)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__gamma\": [0.1 * x for x in range(1, 6)]\n",
    "}\n",
    "\n",
    "classifier_model = GridSearchCV(classifier_pipeline, param_grid, cv=10)\n",
    "classifier_model.fit(X_train, y_train)\n",
    "\n",
    "y_score = classifier_model.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', size=16)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', size=16)\n",
    "plt.title('ROC Curve', size=20)\n",
    "plt.legend(fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get dummy one-hot-encoder: remove collinearilty of one-hot-encoding\n",
    "\n",
    "https://stackoverflow.com/questions/44864408/removing-columns-with-sklearns-onehotencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    \n",
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, n_values='auto'):\n",
    "        self.n_values = n_values\n",
    "\n",
    "    def transform(self, X):\n",
    "        ohe = OneHotEncoder(sparse=False, n_values=self.n_values)\n",
    "        return ohe.fit_transform(X)[:,:-1]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-hot encoder to get columns directly: https://medium.com/hugo-ferreiras-blog/dealing-with-categorical-features-in-machine-learning-1bb70f07262d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ColumnTransformer\n",
    "https://medium.com/dunder-data/from-pandas-to-scikit-learn-a-new-exciting-workflow-e88e2271ef62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> transformers = [('cat', cat_pipe, cat_cols),\n",
    "                    ('num', num_pipe, num_cols)]\n",
    ">>> ct = ColumnTransformer(transformers=transformers)\n",
    ">>> X = ct.fit_transform(train)\n",
    ">>> X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imbalnce pipeline for smote\n",
    "https://bsolomon1124.github.io/oversamp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE  # or: import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     train_test_split,\n",
    "                                     StratifiedKFold)\n",
    "\n",
    "# Generate some data with an 8-to-2 class imbalance.\n",
    "X, y = make_classification(n_features=5, n_samples=75,\n",
    "                           random_state=444, weights=[0.8, 0.2])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=444, stratify=y)\n",
    "\n",
    "# This doesn't work with sklearn.pipeline.Pipeline because\n",
    "# RandomOverSampler doesn't have a .tranform() method.\n",
    "# (It has .fit_sample() or .sample().)\n",
    "pipe = imbPipeline([\n",
    "    ('oversample', SMOTE(random_state=444)),\n",
    "    ('clf', RandomForestClassifier(random_state=444, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "skf = StratifiedKFold()\n",
    "param_grid = {'clf__max_depth': [25, 40],\n",
    "              'clf__max_features': ['sqrt', 'log2']}\n",
    "grid = GridSearchCV(pipe, param_grid, return_train_score=False,\n",
    "                    n_jobs=-1, scoring='roc_auc', cv=skf)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)\n",
    "# 0.9500000000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Custom transformer: labelEncoder to multiple columns\n",
    "\n",
    "  - https://blog.pursuitofzen.com/pipelines-featureunions-gridsearchcv-and-custom-transformers/\n",
    "  - https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there is a link with many custom transfomers (not all correct though)\n",
    "   https://stackoverflow.com/questions/47924363/labelencoder-in-sklearn-pandas-mapper-with-pipeline-after-cross-val-score-return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.base import TransformerMixin #gives fit_transform method for free\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MultiColumnLabelEncoder(TransformerMixin):  \n",
    "    \"\"\"Transformer for applying label encoder on multiple columns.\n",
    "\n",
    "    This transformer applies label encoding to columns in a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.d = defaultdict(LabelEncoder)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\"Transforms X to have columns label encoded.\n",
    "\n",
    "        Args:\n",
    "            X (obj): The dataset to transform. Can be dataframe or matrix.\n",
    "            transform_params (kwargs, optional): Additional params.\n",
    "\n",
    "        Returns:\n",
    "            The transformed dataset with the label encoded columns.\n",
    "        \"\"\"\n",
    "        X = X.fillna('NaN')  # fill null values with 'NaN'\n",
    "        transformed = X.apply(lambda x: self.d[x.name].transform(x))\n",
    "        return transformed\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\"Fits transfomer over X.\n",
    "\n",
    "        Needs to apply fit over the defaultdict so as to retain the\n",
    "        label classes when transforming.\n",
    "        \"\"\"\n",
    "        X = X.fillna('NaN')  # fill null values with 'NaN'\n",
    "        X.apply(lambda x: self.d[x.name].fit(x))\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature importance\n",
    "- explaining feature importances and feature names: library eli5\n",
    "\n",
    "\n",
    "https://github.com/TeamHG-Memex/eli5/blob/master/notebooks/xgboost-titanic.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
