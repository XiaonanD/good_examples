{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://campus.datacamp.com/courses/foundations-of-predictive-analytics-in-python-part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> part 1. choose the right data to use\n",
    "  - timeline\n",
    "  - population\n",
    "  - target\n",
    "\n",
    "> part 2. Adding evolutions\n",
    "    - add trending: YoY metric to track change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Import pandas as pd\n",
    "gifts = pd.read_csv(“gifts.csv”)\n",
    "gifts[\"date\"] = pd.to_datetime(gifts[\"date\"])\n",
    "print(gifts.head())\n",
    "#    id       date  amount\n",
    "# 0   1 2015-10-16    75.0\n",
    "# 1   1 2014-02-11   111.0\n",
    "# 2   1 2012-03-28    93.0\n",
    "# 3   1 2013-12-13   113.0\n",
    "# 4   1 2012-01-10    93.0\n",
    "start_target = datetime(year = 2018, month = 5, day = 1)\n",
    "# reference_date = datetime.date(2018,4,1)\n",
    "end_target = datetime(year = 2018, month = 8, day = 1)\n",
    "gifts_target = gifts[(gifts[\"date\"]>=start_target) & (gifts[\"date\"]<end_target)]\n",
    "gifts_pred_variables = gifts[(gifts[\"date\"]<start_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "population example: people who donate in 2016 but didn't donate in 2017 yet\n",
    "\"\"\"\n",
    "donations_2016 = gifts[gifts[\"date\"].dt.year==2016]\n",
    "donors_include = set(donations_2016[\"id\"])\n",
    "print(donors_include)\n",
    "{1002,3043,4934, ...}\n",
    "donations_2017 = gifts[(gifts[\"date\"].dt.year==2017) \n",
    "                       & (gifts[\"date\"].dt.month<5)]\n",
    "donors_exclude = set(donations_2017[\"id\"])\n",
    "print(donors_exclude)\n",
    "{2451,3047,4474, ...}\n",
    "population = donors_include.difference(donors_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference date\n",
    "reference_date = datetime.date(2018,4,1)\n",
    "# Add lifetime to the basetable\n",
    "basetable[\"lifetime\"] = reference_date - basetable[\"member_since\"]\n",
    "\n",
    "\"\"\"\n",
    "another example of age\n",
    "Add a column \"age\" to the basetable that is the age of the donor on the reference date. \n",
    "\"\"\"\n",
    "\n",
    "# Reference date\n",
    "reference_date = datetime.date(2017, 5, 1)\n",
    "\n",
    "# Add age to the basetable\n",
    "basetable[\"age\"] = (pd.Series([calculate_age(date_of_birth, reference_date)\n",
    "                              for date_of_birth in basetable[\"date_of_birth\"]]))\n",
    "\n",
    "# Calculate mean age\n",
    "print(round(basetable[\"age\"].mean()))\n",
    "# Count the number of donors with no segment assigned\n",
    "print(basetable[\"segment\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding living place, but only use relevant data\n",
    "\"\"\"\n",
    "# Reference date\n",
    "reference_date = datetime.date(2017, 5, 1)\n",
    "\n",
    "# Select living place reference date\n",
    "living_places_reference_date = living_places[(living_places[\"start_date\"] <= reference_date) & \n",
    "                                            (living_places[\"end_date\"] > reference_date)]\n",
    "\n",
    "# Add living place to the basetable\n",
    "basetable = pd.merge(basetable, living_places_reference_date[[\"donor_ID\", \"living_place\"]], on=\"donor_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Part 3. data preparation\n",
    "  - Creating dummies\n",
    "     - prevent multicollinearity - remove one dummy\n",
    "     - dummies_segment = pd.get_dummies(df[\"segment\"],drop_first=True)\n",
    "  - Missing values\n",
    "     - imputation to median/mean\n",
    "     - custom the value\n",
    "  - Outliers: human/machine errors, extreme values\n",
    "     - Winsorization concept: replace low 5/95 percentile to all 5/95 percentile value\n",
    "     - Standard deviation method concept: mean+/- 3sd to replace low/high values\n",
    "  - transformation\n",
    "     - log tranformation: to know numeric difference in order of magnitude\n",
    "     - interactions: one strategy is to include interactions of features of high importance on their own.\n",
    "     - square foot transformation: np.sqrt\n",
    "        - Observe that the differences in the column 'donations_sqrt' are smaller than in the column 'donations_log'. It depends on the situation which one to use, one option could be to add both to the predictive model and let the variable selection algorithm decide which one to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example get dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the dummy variable\n",
    "dummies_country = pd.get_dummies(basetable[\"country\"], drop_first=True)\n",
    "\n",
    "# Add the dummy variable to the basetable\n",
    "basetable = pd.concat([basetable, dummies_country], axis=1)\n",
    "\n",
    "# Delete the original variable from the basetable\n",
    "del basetable[\"country\"]\n",
    "print(basetable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Winsorization to handle outliers\n",
    "example below to 5% highest amounts are replaced by the upper 5% percentile value and top 1 percentile to a fix value\n",
    "\"\"\"\n",
    "from scipy.stats.mstats import winsorize\n",
    "basetable[\"variable_winsorized\"] = \n",
    "     winsorize(\n",
    "       basetable[\"variable\"], \n",
    "       limits = [0.05,0.01])\n",
    "\n",
    "\"\"\"\n",
    "Standard deviation  to handle outliers\n",
    "example below to mean+/- 3sd to replace low/high values\n",
    "\"\"\"  \n",
    "mean_age = basetable[\"age\"].mean()\n",
    "sd_age = basetable[\"age\"].std()\n",
    "lower_limit = mean_age - 3*sd_age\n",
    "upper_limit = mean_age + 3*sd_age\n",
    "basetable[\"age_no_outliers\"] = pd.Series(\n",
    "                                    [min(max(a,lower_limit), upper_limit) \n",
    "                                     for a in basetable[\"age\"]]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Part 4. advanced\n",
    "  - seasonality\n",
    "     - Check for seasonality and use appropriate timeline (predict Jan 2019 then use Jan 2018 rather than May 2018)\n",
    "  - Using multiple snapshots\n",
    "     - if train size is small, then try to include other years' data.\n",
    "  - The timegap: a month as a buffer to prepare. Data in this timegap will not be used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
