{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with Tree-Based Models in Python\n",
    "\n",
    "https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1. classification tree Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  terms\n",
    " - Decision region: region in the feature space where all instances are assigned to one class label.\n",
    " - Decision boundary: surfaces separating different decision regions.\n",
    " \n",
    "\n",
    "> building blocks of a decision-tree: binary tree\n",
    "   - node: question or prediction.\n",
    "     - root: no parent node.\n",
    "     - internal node: one parent node and two children nodes\n",
    "     - leaf: no children - final prediction.\n",
    "     \n",
    "\n",
    "> <font color='blue'>**Information Gain (IG)**</font>\n",
    "   - which feature to pick for splitting: by maximizing information gain.\n",
    "   - two criteria to measure impurity of a node\n",
    "       - ** gini index **\n",
    "       - ** entropy **\n",
    "       - Most of the time, the gini index and entropy lead to the same results. The gini index is slightly faster to compute and is the default criterion used in the \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>advantages of CARTs:</font>\n",
    "  - easy to understand and interpret\n",
    "  - flexibility: able to do non-linear models\n",
    "  - not much preprocessing needed: standardization/scaling etc.\n",
    "   \n",
    "\n",
    "> limitations of CARTs\n",
    "  - classification: can only produce orthogonal decision boundaries\n",
    "  - sensitive to small variations in training sets\n",
    "  - high variances: unconstrained CARTs can overfit the training set\n",
    "  - solution: ensemble learning: more robust and less prone to errors\n",
    "   \n",
    "- from sklearn.tree import DecisionTreeClassifier\n",
    "- from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### information gain\n",
       "<img src = 'ig.png', width = 400, height = 500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### information gain\n",
    "<img src = 'ig.png', width = 400, height = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### information gain for regression\n",
       "<img src = 'ig_regression.png', width = 400, height = 500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### information gain for regression\n",
    "<img src = 'ig_regression.png', width = 400, height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. The Bias-Variance Tradeoff\n",
    "    - Overfitting v.s. underfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1) Generalization error of function f = bias **2 + variance + irreducible error\n",
    "   - Bias: high bias leads to underfitting. \n",
    "         - Not complicated enough to capture insights. \n",
    "         - both large training and test errors.\n",
    "   - Variance: high variance leads to overfitting. \n",
    "\n",
    "\n",
    "\n",
    "> 2) <font color='blue'>**Diagose Variance problem**</font> \n",
    "   - if f function suffers from high variance: CV error of f > training set error of f\n",
    "     - f is said to overfit the training set. To remedy this:\n",
    "        - decrease model complexity\n",
    "        - for ex.: decrease max depth, increase min samples per leaf, ...\n",
    "        - gather more data...\n",
    "\n",
    "   \n",
    "> 3) Diagose bias problem\n",
    "   - if f function suffers from high bias: CV error of f = training set error of f >> desired error\n",
    "     - f is said to underfit the training set. To remedy this:\n",
    "        - increae model complexity\n",
    "        - for ex.: increase max depth, decrease min samples per leaf, ...\n",
    "        - gather more relavant features..\n",
    "\n",
    " \n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### bias and variance\n",
       "<img src = 'bias_var.png', width = 400, height = 500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### bias and variance\n",
    "<img src = 'bias_var.png', width = 400, height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example to diagonose whether overfitting v.s. underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth= 4, min_samples_leaf=0.26, random_state=SEED)\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv= 10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(0.5)\n",
    "\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "RMSE_train = (mean_sqaure_error(y_train, y_pred_train))**(0.5)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))\n",
    "\n",
    "# Print RMSE_train\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** Ensemble example: voting classifer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr)\n",
    "               , ('K Nearest Neighbours', knn)\n",
    "               , ('Classification Tree', dt)]\n",
    "\n",
    "# evaluate each classifier\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import VotingCLassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 3. Bagging\n",
    "** Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. **\n",
    "   - Base estimator can be tree, logistic regression, knn, etc.\n",
    "   - estimators use all features for training and prediction\n",
    " \n",
    "\n",
    "   - bagging: bootstrap aggregation\n",
    "       - bootstrap: sample with replacement\n",
    "   - reduce variance of individual models in ensembles\n",
    "   - do a bootstrap of samples (subset of training set)\n",
    "   - Do a bagging, some samples are used multiple times and others are not sampled at all.\n",
    "   \n",
    "   \n",
    "> 1) Bagging in classification and regression\n",
    "   - Classification:\n",
    "      - aggregates prediction by **majority voting**.\n",
    "      - BaggingClassifier in sklearn \n",
    "   - Regression:\n",
    "      - aggregates prediction by **averaging**.\n",
    "      - BaggingRegresser in sklearn \n",
    "\n",
    " ###### bagging v.s. voting classifer\n",
    " - bagging to do majority/averaging to get prediction--sklearn: BaggingClassifier\n",
    " - votingclassifier to from sklearn.ensemble import VotingClassifier is for majority rule voting (If ‘hard’)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple example of bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratefy = y ,test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2) ** Out of bag (OOB) evaluation**\n",
    ": We don't need to do cross-validation if we enable OOB in ensemble modeling, because OOB samples in each training is untouched.\n",
    "   - On average, 63% of training samples are samples on each model. -- bagging\n",
    "   - The remaining 37% constitute the OOB instances\n",
    "   - each algorithm, use OOB samples to evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### Out of bag evaluation\n",
       "<img src = 'oob.png', width = 400, height = 500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### Out of bag evaluation\n",
    "<img src = 'oob.png', width = 400, height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example of OOB evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf= 8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)\n",
    "\n",
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Random Forest\n",
    "\n",
    "  - base estimator: decision tree\n",
    "  - each estimator is trained on a different boostrap sample having the same size as traning set\n",
    "  - RF introduces further randomization: only use subset of d features(d < total features) without replacement\n",
    "  \n",
    "> 1) RF in classification and regression\n",
    "   - Classification:\n",
    "      - aggregates prediction by **majority voting**.\n",
    "      - RandomForestClassifier in sklearn \n",
    "   - Regression:\n",
    "      - aggregates prediction by **averaging**.\n",
    "      - RandomForestRegresser in sklearn \n",
    "\n",
    "\n",
    "> 2) Feature importance\n",
    "   - how much the tree nodes use a particular feature(weighted average) to reduce impurity\n",
    "   \n",
    "- for randomForestRegressor, its default metric is 'R2', if we want to use mse as metric to evaluate performance, we choose scoring = 'neg_mean_square_error', it is intended to use negative MSE, so model can maximize the metrics.\n",
    "\n",
    "grid_rf = GridSearchCV(estimator = rf, scoring = 'neg_mean_sqaure_error', cv = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a simple random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratefy = y ,test_size=0.3, random_state=SEED)\n",
    "\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) \n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = (MSE(y_pred, y_test))**(0.5)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Plot feature importance\n",
    "\"\"\"\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='bar', color ='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5. Boosting\n",
    "\n",
    "  - base estimator can be anything: decision tree is popular\n",
    "  - boosting combines many weaker learners to form a strong learner.\n",
    "  - Train an ensemble of predictors sequetially and each predictor tries to correct its predecessor.\n",
    "  \n",
    "> 1) Ada boosting (adaptive boosting)\n",
    "   - each predictor pays more attention to the instances wrongly predicted by its predecessor.\n",
    "   - achieved by **changing the weights of traning instances ** (more weights to wrongly predicted labels)\n",
    "   - each predictor is assigned to a coefficient alpha and alpha depends on the predictor's training error.\n",
    "   - <font color='blue'>a tradeoff between number of estimators and learning rate.</font>\n",
    "\n",
    "    - Classification:\n",
    "      - aggregates prediction by **Weighted majority voting**.\n",
    "      - AdaBoostClassifier in sklearn \n",
    "    - Regression:\n",
    "      - aggregates prediction by **weigthed averaging**.\n",
    "      - AdaBoostRegresser in sklearn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- example to use adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)\n",
    "\n",
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba =ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ** 2) Gradient boosting **\n",
    "   - sequential correction of predecessor's errors.\n",
    "   - does NOT tweak the weights of training instances.\n",
    "   - each predictor is trained using its predecessor's residual errors as labels.\n",
    "   - Gradient boosting trees: a CART tree as base estimator\n",
    "   - <font color='blue'>a tradeoff between shrikage and num of estimators.**</font>\n",
    "   \n",
    "GB cons: \n",
    "- involves an exhaustive search process\n",
    "- each tree is trained to find its best split points and features, which may lead CARTs using the same split points and the same features. To metigates this:\n",
    "\n",
    "\n",
    "> ** 3) Stochastic Gradient boosting **\n",
    "   - each tree is trained on a random subset rows of training data.\n",
    "   - the sampled instances (40% - 80% of the training set) are sampled without replacement.\n",
    "   - features are sampled(without replacement) when choosing split points.\n",
    "   - result: create further diversity of ensemble.\n",
    "   - effect: add more variance to the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### Gradient boosting\n",
       "<img src = 'grad_boost.png', width = 500, height = 600>\n",
       "\n",
       "<img src = 'gra_boost_cl.png', width = 500, height = 600>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### Gradient boosting\n",
    "<img src = 'grad_boost.png', width = 500, height = 600>\n",
    "\n",
    "<img src = 'gra_boost_cl.png', width = 500, height = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### example of gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth=4, \n",
    "            n_estimators=200,\n",
    "            random_state=2)\n",
    "\n",
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### example of stachastic gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,  # each tree only use 90% of samples\n",
    "            max_features=0.85, # max 85% of features\n",
    "            n_estimators=200,                                \n",
    "            random_state=2)\n",
    "\n",
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)\n",
    "\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = mse_test**(0.5)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6. Model Tuning\n",
    "\n",
    " - hyperparameters: not learnt from data, set prior to training\n",
    " - approches to hyperparamter tuning: Grid Search, Random Search, Bayesian optimization, Genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = 1\n",
    "dt = DecisionTreeClassifier(random_state= seed)\n",
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a simple gridsearch example using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = 1\n",
    "dt = DecisionTreeClassifier(random_state= seed)\n",
    "\n",
    "# Define params_dt\n",
    "params_dt = {'max_depth':[2,3,4]\n",
    "             , 'min_samples_leaf': [0.12,0.14,0.16,0.18]\n",
    "}\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba) \n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- simple example using random forest regressor for gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratefy = y ,test_size=0.3, random_state=SEED)\n",
    "\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {'n_estimators': [100,350,500]\n",
    "             , 'max_features':['log2','auto','sqrt']\n",
    "             , 'min_samples_leaf':[2,10,30]\n",
    "}\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_pred, y_test)**(0.5)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
