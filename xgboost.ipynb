{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://campus.datacamp.com/courses/extreme-gradient-boosting-with-xgboost/fine-tuning-your-xgboost-model?ex=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1. XGboost overall and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** 1. evaluation **\n",
    "     - binary classification: ROC_AUC is the most popular metrics to evaluate model performance\n",
    "     - multi-class classification: commonly to use accuracy to evaluate model performance\n",
    "     \n",
    "> ** 2. other supervised learning considerations  **\n",
    "     - features can be either numeric or catergorical\n",
    "     - numeric features should be scaled (Z-scored)\n",
    "     - categorical features should be encoded(one-hot/dummy).\n",
    "     \n",
    "> ** 3. why XGboost **\n",
    "     - Optimized gradient-boosting machine learning library\n",
    "     - originally written in C++, now has APIs in several languages: python, R, scala, Java, etc.\n",
    "     - speed and performance\n",
    "     - core algorithm is parallelable\n",
    "     - consistently outperforms other single algorithm\n",
    "\n",
    "> ** 4. Decision tree **\n",
    "     - Constructed iteratively (one decision at a time)\n",
    "        - split is to segregate target value better, put each category is nearly one bucket\n",
    "        - until a stopping criterion is met\n",
    "        - low bias and high variance model- overfitting\n",
    "\n",
    "> **5. When to use XGboost **\n",
    "  - large training examples (datasize > 100, and feature < 100): as long as num_feature < num_data\n",
    "  - xgboost tends to do well in a mix of categorical and numeric features, or only numeric\n",
    "\n",
    "> ** 6. When NOT to use XGboost **\n",
    "  - image recoginition\n",
    "  - computer vision\n",
    "  - NLP and understanding problems\n",
    "  - deep learning fits examples above better\n",
    "  - small sample size or num_feature > num_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "url_link = 'https://assets.datacamp.com/production/repositories/943/datasets/4dbcaee889ef06fb0763e4a8652a4c1f268359b2/ames_housing_trimmed_processed.csv'\n",
    "housing_data = pd.read_csv(url_link)\n",
    "X, y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
    "housing_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "simple example using decision tree\n",
    "\"\"\"\n",
    "# Import the necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the classifier: dt_clf_4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth = 4)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "dt_clf_4.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred_4\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions: accuracy\n",
    "accuracy = float(np.sum(y_pred_4==y_test))/y_test.shape[0]\n",
    "print(\"accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is boosting\n",
    "   - Meta algorithm: ensemble method to combine many weak learners to form a strong learner.\n",
    "\n",
    "> Model evaluation through cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-example: Perform 3-fold cross-validation by calling xgb.cv(). dtrain is your churn_dmatrix, params is your parameter dictionary, folds is the number of cross-validation folds (3), num_boosting_rounds is the number of trees we want to build (5), metrics is the metric you want to compute (this will be \"error\", which we will convert to an accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
    "\n",
    "# Create the DMatrix: churn_dmatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "# objective here is to choose loss function and booster can choose base learner\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "# num_boosting_rounds is the number of trees we want to build\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=5, metrics=\"error\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the accuracy\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute another common metric used in binary classification - the area under the curve (\"auc\"). \n",
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3\n",
    "                    , num_boost_round=5, metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "# four columns: test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2. XGboost regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** 1. regression basics **\n",
    "     - common regression metrics: \n",
    "        - root mean square error (RMSE)\n",
    "        - mean absolute error (MAE)\n",
    "> ** 2. Objective (loss) functions and base learners **\n",
    "     - loss functions and why we use them:\n",
    "        - quantify how far off a prediction is from actual results\n",
    "        - measures the difference between predicted and true data\n",
    "        - goal: minimize loss function\n",
    "     - common loss function in XGboost:\n",
    "        - 'reg:linear': use for regression problems\n",
    "        - 'reg:logistic': use for classification problems, when simply want prediction, not probability\n",
    "        - 'binary:logistic': use for classification problems, when want probability rather than decision\n",
    "\n",
    "> ** 3. base learners and why we need them **\n",
    "     - XGboost creates a meta-model that is composed of many individual models to a final prediction\n",
    "     - base learners = individual models\n",
    "     - want base learners when combined finally is non-linear\n",
    "     - each learner should be good at distinguishing or predicting different parts of the dataset\n",
    "     - By default, XGBoost uses trees as base learners, so you don't have to specify that you want to use trees here with booster=\"gbtree\". But if you want to use linear base learner, params = {\"objective\":\"reg:linear\", \"booster\":'gblinear'}\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22773.438540\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "use tree as base learners for regression\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBRegressor: xg_reg\n",
    "xg_reg = xgb.XGBRegressor(objective= \"reg:linear\", num_estimators = 10, random_state = 123)\n",
    "\n",
    "# Fit the regressor to the training set\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "# Compute the rmse: rmse\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color='blue'>** use linear base learner to do xgb regression **</font>\n",
    "- This model, although not as commonly used in XGBoost, allows you to create a regularized linear regression using XGBoost's powerful learning API. However, because it's uncommon, you have to use XGBoost's own non-scikit-learn compatible functions to build the model, such as xgb.train()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 44331.645061\n"
     ]
    }
   ],
   "source": [
    "# Convert the training and testing sets into DMatrixes: DM_train, DM_test\n",
    "DM_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "DM_test =  xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(dtrain =DM_train, params = params, num_boost_round=5)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(DM_test)\n",
    "\n",
    "# Compute and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:10:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "   test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
      "0   142980.433594    1193.791602    141767.531250      429.454591\n",
      "1   104891.394532    1223.158855    102832.544922      322.469930\n",
      "2    79478.937500    1601.344539     75872.615235      266.475960\n",
      "3    62411.920899    2220.150028     57245.652343      273.625086\n",
      "4    51348.279297    2963.377719     44401.298828      316.423666\n",
      "4    51348.279297\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "# can change metrics = 'rmse' to 'mae'\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, \n",
    "                    metrics='rmse', as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "> ** 4. Regularization in XGboost**\n",
    "     - regularization in a control of model complexity: we want model accurate and as simple as possible\n",
    "     - regularization paramters in XGboost by altering loss function:\n",
    "        - gamma: minimize loss function allowed for a split to occur. higher gamma, fewer split.\n",
    "        - alpha: l1 regularization on leaf weights(not on feature weights), larger values mean more regularized. high value leads many leaf weights to 0. \n",
    "        - lamda: l2 regularization on leaf weights. smooth decrease on leaf weights, instead of creating sparsity as l1.\n",
    "        \n",
    "\n",
    "> ** 5. Base learners in XGBoost** \n",
    "   - Linear base learner\n",
    "      - Sum of linear terms\n",
    "      - Boosted model is weighted  sum of linear models (thus itself linear)\n",
    "      - Rarely used\n",
    "   - Tree base learner:\n",
    "      - Decision tree\n",
    "      - Boosted model is weighted sum of decision trees (nonlinear)\n",
    "      - Almost exclusively used in XGBoost\n",
    "\n",
    "     \n",
    "     \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example1:  to do l2 regularization penalty - also known as \"lambda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "reg_params = [1, 10, 100]\n",
    "\n",
    "# Create the initial parameter dictionary for varying l2 strength: params\n",
    "params = {\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create an empty list for storing rmses as a function of l2 complexity\n",
    "rmses_l2 = []\n",
    "\n",
    "# Iterate over reg_params\n",
    "for reg in reg_params:\n",
    "\n",
    "    # Update l2 strength\n",
    "    params[\"lambda\"] = reg\n",
    "    \n",
    "    # Pass this updated param dictionary into cv\n",
    "    cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append best rmse (final round) to rmses_l2\n",
    "    rmses_l2.append(cv_results_rmse[\"test-rmse-mean\"].tail(1).values[0])\n",
    "\n",
    "# Look at best rmse per l2 param\n",
    "print(\"Best rmse as a function of l2:\")\n",
    "print(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=[\"l2\", \"rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- example 2: Visualizing individual XGBoost trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath    ...      \\\n",
       "0          0       1710             1             0    ...       \n",
       "1          0       1262             0             1    ...       \n",
       "\n",
       "   HouseStyle_1.5Unf  HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  1                  0                  0   \n",
       "\n",
       "   HouseStyle_2Story  HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  \\\n",
       "0                  1                  0                0             0   \n",
       "1                  0                  0                0             0   \n",
       "\n",
       "   PavedDrive_Y  SalePrice  \n",
       "0             1     208500  \n",
       "1             1     181500  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_link = 'https://assets.datacamp.com/production/repositories/943/datasets/4dbcaee889ef06fb0763e4a8652a4c1f268359b2/ames_housing_trimmed_processed.csv'\n",
    "housing_data = pd.read_csv(url_link)\n",
    "X, y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
    "housing_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":2}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
    "\n",
    "# Plot the first tree\n",
    "xgb.plot_tree(xg_reg, num_trees =0 )\n",
    "plt.show()\n",
    "\n",
    "# Plot the fifth tree\n",
    "xgb.plot_tree(xg_reg, num_trees =4 )\n",
    "plt.show()\n",
    "\n",
    "# Plot the last tree sideways\n",
    "xgb.plot_tree(xg_reg, num_trees =9, rankdir = 'LR' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example 3: feature importance\n",
    "    - One simple way of doing this involves counting the number of times each feature is split on across all boosting rounds (trees) in the model, and then visualizing the result as a bar graph, with the features ordered according to how many times they appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[14:08:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEWCAYAAACkI6QfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2qgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11abfd650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data = X, label = y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {'objective':'reg:linear', 'max_depth': 4}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(dtrain = housing_dmatrix, num_boost_round= 10, params = params)\n",
    "\n",
    "# Plot the feature importances\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## part 3. Fine-tuning XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example 1. manual fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data = X, label = y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Automated boosting round selection using early_stopping **\n",
    "  - Now, instead of attempting to cherry pick the best possible number of boosting rounds, you can very easily have XGBoost automatically select the number of boosting rounds for you within xgb.cv(). This is done using a technique called early stopping.\n",
    "  - Early stopping works by testing the XGBoost model after every boosting round against a hold-out dataset and stopping the creation of additional boosting rounds (thereby finishing training of the model early) if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds. Here you will use the early_stopping_rounds parameter in xgb.cv() with a large possible number of boosting rounds (50). Bear in mind that if the holdout metric continuously improves up through when num_boosting_rounds is reached, then early stopping does not occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example 2. early stopping \n",
    "  -Perform 3-fold cross-validation with early stopping and \"rmse\" as your metric. Use 10 early stopping rounds and 50 boosting rounds. Specify a seed of 123 and make sure the output is a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation with early stopping: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3,early_stopping_rounds= 10, num_boost_round= 50, seed = 123, as_pandas= True)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** Common tree tunable parameters **\n",
    "  - learning rate(eta): how quickly the model fit the residual error using an additional base learner. \n",
    "        low learning rates, more rounds of learnings\n",
    "  - regularization paramters:\n",
    "        - gamma: minimize loss function allowed for a split to occur. higher gamma, fewer split.\n",
    "        - alpha: l1 regularization on leaf weights(not on feature weights), larger values mean more regularized. high value leads many leaf weights to 0. \n",
    "        - lamda: l2 regularization on leaf weights. smooth decrease on leaf weights, instead of creating sparsity as l1.\n",
    "  - max_depth: how deep each tree can be. max depth per tree.\n",
    "  - subsample: % samples used per tree. low value can leads to underfitting, very high value might lead to overfitting.\n",
    "  - colsample_bytree: % of features used per tree. small value here generally means providing additional regularization in each model. while larger value could end up with overfitting. the same as max_features in random forest\n",
    "  \n",
    "  \n",
    "  \n",
    "> ** linear tunable parameters **\n",
    "  - lambda: l2 regularization\n",
    "  - alpha: l1 regularization\n",
    "  - lambda_bias: L2 reg terms on bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example tuning learning rate: eta\n",
    "higher values of \"eta\" penalizing feature weights more strongly, causing much stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree (boosting round)\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the eta \n",
    "for curr_val in eta_vals:\n",
    "\n",
    "    params[\"eta\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=10, early_stopping_rounds= 5,  metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2, 5, 10, 20]\n",
    "# colsample_bytree_vals = [0.1, 0.5, 0.8,1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the max_depth\n",
    "for curr_val in max_depths:\n",
    "\n",
    "    params[\"max_depth\"] = curr_val\n",
    "    \n",
    "#     params['colsample_bytree'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=10, early_stopping_rounds= 5,  metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Review of GridSearch and RandomSearch\n",
    "   - GridSearch: search exhausively over a given set of hyperparameters. \n",
    "   - RandomSearch: \n",
    "       - create a (possible infinite) range of hyperparameter values per hyperparameter that you would love to search over \n",
    "       - set the number of iterations that you like\n",
    "       - randomly draw a value in the list in each hyperparamter and train/evaluate model using those hyperparameters.\n",
    "       \n",
    "\n",
    "> Limits of GridSearch and RandomSearch\n",
    "    - GridSearch: can be time consuming when too many choices of hyperparamter combinations.\n",
    "    - Random Search: parameter space to explore can be massive; randomly jumping throughout the space to look for 'best' result becomes a waiting game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example of xgb in gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(estimator = gbm, param_grid= gbm_param_grid, scoring = 'neg_mean_squared_error', cv = 4, verbose = 1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X, y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RandomSearch in xgb\n",
    "\"\"\"\n",
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [25],\n",
    "    'max_depth': range(2, 12)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "randomized_mse = RandomizedSearchCV(estimator = gbm, param_distributions= gbm_param_grid, scoring = 'neg_mean_squared_error', n_iter = 5, cv = 4, verbose = 1)\n",
    "\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "randomized_mse.fit(X, y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>Y</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>Y</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Neighborhood BldgType HouseStyle  \\\n",
       "0          60       RL         65.0     8450      CollgCr     1Fam     2Story   \n",
       "1          20       RL         80.0     9600      Veenker     1Fam     1Story   \n",
       "\n",
       "   OverallQual  OverallCond  YearBuilt    ...     GrLivArea  BsmtFullBath  \\\n",
       "0            7            5       2003    ...          1710             1   \n",
       "1            6            8       1976    ...          1262             0   \n",
       "\n",
       "   BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  Fireplaces  GarageArea  \\\n",
       "0             0         2         1             3           0         548   \n",
       "1             1         2         0             3           1         460   \n",
       "\n",
       "   PavedDrive SalePrice  \n",
       "0           Y    208500  \n",
       "1           Y    181500  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://assets.datacamp.com/production/course_6611/datasets/ames_unprocessed_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoding categorical columns I: LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSZoning Neighborhood BldgType HouseStyle PavedDrive\n",
      "0       RL      CollgCr     1Fam     2Story          Y\n",
      "1       RL      Veenker     1Fam     1Story          Y\n",
      "2       RL      CollgCr     1Fam     2Story          Y\n",
      "3       RL      Crawfor     1Fam     2Story          Y\n",
      "4       RL      NoRidge     1Fam     2Story          Y\n",
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == object)\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoding categorical columns II: OneHotEncoder\n",
    "    - labelencoder: allowing the model to assume this natural ordering may result in poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 21)\n",
      "(1460, 62)\n"
     ]
    }
   ],
   "source": [
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(categorical_features = categorical_mask, sparse = False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "# print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** DictVectorizer**: Using a DictVectorizer on a DataFrame that has been converted to a dictionary allows you to get label encoding as well as one-hot encoding in one go.\n",
    "\n",
    "DictVectorizer has useful attributes such as vocabulary_ which maps the names of the features to their indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>Y</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>Y</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Neighborhood BldgType HouseStyle  \\\n",
       "0          60       RL         65.0     8450      CollgCr     1Fam     2Story   \n",
       "1          20       RL         80.0     9600      Veenker     1Fam     1Story   \n",
       "\n",
       "   OverallQual  OverallCond  YearBuilt    ...     GrLivArea  BsmtFullBath  \\\n",
       "0            7            5       2003    ...          1710             1   \n",
       "1            6            8       1976    ...          1262             0   \n",
       "\n",
       "   BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  Fireplaces  GarageArea  \\\n",
       "0             0         2         1             3           0         548   \n",
       "1             1         2         0             3           1         460   \n",
       "\n",
       "   PavedDrive SalePrice  \n",
       "0           Y    208500  \n",
       "1           Y    181500  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://assets.datacamp.com/production/course_6611/datasets/ames_unprocessed_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 2.000e+00 5.480e+02 1.710e+03 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  8.450e+03 6.500e+01 6.000e+01 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e+00 7.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 2.085e+05 2.003e+03]]\n",
      "{'Neighborhood=NridgHt': 45, 'BsmtFullBath': 6, 'Neighborhood=Timber': 52, 'HalfBath': 12, 'HouseStyle=2.5Fin': 16, 'MSZoning=FV': 25, 'OverallCond': 54, 'LotArea': 21, 'Neighborhood=Sawyer': 48, 'Neighborhood=CollgCr': 34, 'HouseStyle=SFoyer': 19, 'GrLivArea': 11, 'HouseStyle=1.5Unf': 14, 'BldgType=Twnhs': 4, 'MSZoning=RM': 28, 'BldgType=TwnhsE': 5, 'Fireplaces': 8, 'MSZoning=RL': 27, 'LotFrontage': 22, 'Neighborhood=BrkSide': 32, 'OverallQual': 55, 'Neighborhood=OldTown': 46, 'FullBath': 9, 'BsmtHalfBath': 7, 'Neighborhood=StoneBr': 51, 'MSZoning=RH': 26, 'Neighborhood=Crawfor': 35, 'MSZoning=C (all)': 24, 'Neighborhood=ClearCr': 33, 'HouseStyle=1Story': 15, 'PavedDrive=P': 57, 'Neighborhood=SawyerW': 49, 'BldgType=2fmCon': 2, 'Neighborhood=NWAmes': 43, 'PavedDrive=Y': 58, 'Remodeled': 59, 'Neighborhood=NAmes': 41, 'Neighborhood=Veenker': 53, 'MSSubClass': 23, 'YearBuilt': 61, 'Neighborhood=Blmngtn': 29, 'Neighborhood=NPkVill': 42, 'PavedDrive=N': 56, 'Neighborhood=IDOTRR': 38, 'Neighborhood=Somerst': 50, 'Neighborhood=BrDale': 31, 'Neighborhood=Blueste': 30, 'BedroomAbvGr': 0, 'Neighborhood=Mitchel': 40, 'HouseStyle=1.5Fin': 13, 'Neighborhood=NoRidge': 44, 'BldgType=Duplex': 3, 'HouseStyle=SLvl': 20, 'Neighborhood=Gilbert': 37, 'Neighborhood=MeadowV': 39, 'Neighborhood=Edwards': 36, 'HouseStyle=2Story': 18, 'GarageArea': 10, 'HouseStyle=2.5Unf': 17, 'BldgType=1Fam': 1, 'Neighborhood=SWISU': 47, 'SalePrice': 60}\n"
     ]
    }
   ],
   "source": [
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "df_dict = df.to_dict(orient = 'records')\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer(sparse = False)\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "# Print the resulting first five rows\n",
    "print(df_encoded[:1,:])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ohe_onestep', DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('xgb_model', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_chi...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline\n",
    "xgb_pipeline.fit(X.to_dict(\"records\"), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final: Using XGBoost in pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10-fold RMSE: ', 29867.603720688923)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate the model\n",
    "cross_val_scores = cross_val_score(xgb_pipeline, X.to_dict('records'),y, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "\n",
    "# Print the 10-fold RMSE\n",
    "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "gbm_param_grid = {\n",
    "    'clf__learning_rate': np.arange(0.05, 1, 0.05),\n",
    "    'clf__max_depth': np.arange(3, 10, 1),\n",
    "    'clf__n_estimators': np.arange(50, 200, 50)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "randomized_roc_auc = RandomizedSearchCV(pipeline, param_distributions= gbm_param_grid, scoring = 'roc_auc', verbose = 1, n_iter = 2)\n",
    "\n",
    "# Fit the estimator\n",
    "randomized_roc_auc.fit(X,y)\n",
    "\n",
    "# Compute metrics\n",
    "print(randomized_roc_auc.best_score_)\n",
    "print(randomized_roc_auc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case study: kidney disease\n",
    "   - The chronic kidney disease dataset contains both categorical and numeric features, but contains lots of missing values. The goal here is to predict who has chronic kidney disease given various blood indicators as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp    sg   al   su  rbc      pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.02  1.0  0.0  NaN  normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.02  4.0  0.0  NaN  normal  notpresent  notpresent   \n",
       "\n",
       "       ...        pcv    wc   rc  htn   dm  cad appet  pe ane classification  \n",
       "0      ...         44  7800  5.2  yes  yes   no  good  no  no            ckd  \n",
       "1      ...         38  6000  NaN   no   no   no  good  no  no            ckd  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url_kidney = 'https://assets.datacamp.com/production/course_6611/datasets/chronic_kidney_disease.csv'\n",
    "data = pd.read_csv('kidney_disease.csv')\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impute missing categorical values directly using the Categorical_Imputer() class in sklearn_pandas, and the DataFrameMapper() class to apply any arbitrary sklearn-compatible transformer on DataFrame columns, where the resulting output can be either a NumPy array or DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Check number of nulls in each feature column\n",
    "nulls_per_column = X.isnull().sum()\n",
    "# print(nulls_per_column)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_feature_mask = X.dtypes == object\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "# Get list of non-categorical column names\n",
    "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
    "\n",
    "# Apply numeric imputer\n",
    "numeric_imputation_mapper = DataFrameMapper(\n",
    "                                            [([numeric_feature], Imputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
    "                                            input_df=True,\n",
    "                                            df_out=True\n",
    "                                           )\n",
    "\n",
    "# Apply categorical imputer\n",
    "categorical_imputation_mapper = DataFrameMapper(\n",
    "                                                [(category_feature, CategoricalImputer()) for category_feature in categorical_columns],\n",
    "                                                input_df=True,\n",
    "                                                df_out=True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- scikit-learn's FeatureUnion to concatenate their results, which are contained in two separate transformer objects - numeric_imputation_mapper, and categorical_imputation_mapper, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Combine the numeric and categorical transformations\n",
    "numeric_categorical_union = FeatureUnion([\n",
    "                                          (\"num_mapper\", numeric_imputation_mapper),\n",
    "                                          (\"cat_mapper\", categorical_imputation_mapper)\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "It's time to piece together all of the transforms along with an XGBClassifier to build the full pipeline!\n",
    "\n",
    "Besides the numeric_categorical_union that you created in the previous exercise, there are two other transforms needed: the Dictifier() transform which we created for you, and the DictVectorizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create full pipeline\n",
    "\n",
    "\"\"\"\n",
    "(\"dictifier\", Dictifier()) is a personal function\n",
    "X = X.to_dict('records')\n",
    "\"\"\"\n",
    "pipeline = Pipeline([\n",
    "                     (\"featureunion\", numeric_categorical_union),\n",
    "                     (\"dictifier\", Dictifier()),\n",
    "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
    "                     (\"clf\", xgb.XGBClassifier(max_depth=3))\n",
    "                    ])\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(pipeline, kidney_data, y, scoring=\"roc_auc\", cv=3)\n",
    "\n",
    "# Print avg. AUC\n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "gbm_param_grid = {\n",
    "    'clf__learning_rate': np.arange(0.05, 1, 0.05),\n",
    "    'clf__max_depth': np.arange(3, 10, 1),\n",
    "    'clf__n_estimators': np.arange(50, 200, 50)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "randomized_roc_auc = RandomizedSearchCV(pipeline, param_distributions= gbm_param_grid, scoring = 'roc_auc', verbose = 1, n_iter = 2)\n",
    "\n",
    "# Fit the estimator\n",
    "randomized_roc_auc.fit(X,y)\n",
    "\n",
    "# Compute metrics\n",
    "print(randomized_roc_auc.best_score_)\n",
    "print(randomized_roc_auc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### not covered\n",
       "<img src = 'not_covered.png', width = 400, height = 500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### not covered\n",
    "<img src = 'not_covered.png', width = 400, height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- debug and understand DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'BedroomAbvGr': 3,\n",
       "  'BldgType': '1Fam',\n",
       "  'BsmtFullBath': 1,\n",
       "  'BsmtHalfBath': 0,\n",
       "  'Fireplaces': 0,\n",
       "  'FullBath': 2,\n",
       "  'GarageArea': 548,\n",
       "  'GrLivArea': 1710,\n",
       "  'HalfBath': 1,\n",
       "  'HouseStyle': '2Story',\n",
       "  'LotArea': 8450,\n",
       "  'LotFrontage': 65.0,\n",
       "  'MSSubClass': 60,\n",
       "  'MSZoning': 'RL',\n",
       "  'Neighborhood': 'CollgCr',\n",
       "  'OverallCond': 5,\n",
       "  'OverallQual': 7,\n",
       "  'PavedDrive': 'Y',\n",
       "  'Remodeled': 0,\n",
       "  'SalePrice': 208500,\n",
       "  'YearBuilt': 2003}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "df_dict = df.to_dict(orient = 'records')\n",
    "df_dict[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1Fam', '2fmCon', 'Duplex', 'TwnhsE', 'Twnhs'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.BldgType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "a     1  0.50\n",
       "b     2  0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(\n",
    "        {'col1': [1, 2], 'col2': [0.5, 0.75]}, index=['a', 'b'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.05, 1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
